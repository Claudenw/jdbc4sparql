Complete functionality has not been tested.  However, most code is functional and testing should 
be completed in the near future.

# JDBC 4 SPARQL

JDBC 4 SPARQL is a JDBC Driver that uses a SPARQL endpoint (or Jena Model) as the data store.

## Licenses

JDBC 4 SPARQL is licensed under Apache License V2.  However, there is one component that is Licensed under the GNU LGPL V3.0
this means that if you want to use this product in an environment that is not permitted under GNU LGPL V3.0 you will need to 
find another implementation of the SparqlParser interface.  How to do this is covered in the Extensions Points section of this 
document.
	
## Maven

Group ID: org.xenei

Artifact ID: jdbc4sparql

## Usage

### URL
The URL for the J4SDriver is 
    jdbc:j4s:[?arg=value>[&arg2=value2[&arg3=value3...]]]:url

For current runtime configuration options and defaults execute the J4SDriver class as an application.

#### Valid arguments
* catalog The name of the catalogue to restrict queries for.
* type The type of the input.
* builder The builder to build the SQL Schema with.  Either the name of a registered builder or a class name.  See "Registered Schema Builders" below.
* parser The parser class.  A fully qualified SparqlParser implementation.  Defaults to org.xenei.jdbc4sparql.sparql.parser.jsqlparser.SparqlParserImpl

#### Valid Types:
* (Default) config - URL is a J4S configuration file (NOT YET IMPLEMENTED)
* sparql - URL is a sparql endpoint
* RDFXML or RDF/XML - URL is a RDF/XML formatted RDF file
* NTRIPLES or N-Triples - URL is a N-Triples formatted RDF file
* N3 or N3 - URL is a N3 formatted RDF file
* TURTLE or Turtle - URL is a Turtle formatted RDF file
* RDFJSON or RDF/JSON - URL is a RDF/JSON formatted RDF file
* NQUADS or N-Quads - URL is a N-Quads formatted RDF file
* TRIG or TriG - URL is a TriG formatted RDF file

#### Registered Schema Builders
(Default) Simple_Builder: A simple schema builder that builds tables based on RDFS Class names

#### Notes ####

Currently the catalogue is built at runtime by the builder, however future improvements should include a mechanism to store an entire configuration of multiple catalogues.

the Catalogue contains the URL for the SPARQL endpoint or RDF file so it will be possible to configure the driver to access multiple endpoints.

## A Conflict Of Nomenclatures

SQL and SPARQL use nomenclatures that conflict with each other.  For the purposes of this documentation, unless otherwise specified,
SQL nomenclatures will be used.

## How This Works

### Mapping The Graph
In general an RDF Graph (and thus a SPARQL endpoint) is an instance of a navigational database, SQL is generally designed to work
against a relational model so there this application attempts to map a navigational database onto relational tables and keys.  It 
does this through the use of a "SchemaBuilder" implementation to map the RDF Graph to tables and columns.
The default implementation looks for RDF resources that have a rdf:type of rdfs:Class.  It considers 
each of these resources as tables and uses the resource name as the table name, we will call these "Table Resources".  It then scans the 
RDF store looking for distinct properties of objects of the "Table Resource" types.  The properties are the columns in the table.  All tables generated by the "SchemaBuilder" are 
stored in a SQL Schema, so multiple schemas may be created from a single RDF Schema, Vocabulary or datastore.

It is possible to override the default implementation by implementing a new SchemaBuilder and adding it to the /META-INF/services/org.xenei.jdbc4sparql.sparql.builders.SchemaBuilder file.
The first entry in the file is considered the default builder.

### Generating A Query
A SQL query is parsed by a "SparqlParser" implementation the and converted into a SPARQL query.  
The default implementation of SparqlParser is LGPL v3 and uses an LGPL v2.1 based package.  Other implementations may be used.
To register a different implementation place it as the first entry in the /META-INF/services/org.xenei.jdbc4sparql.sparql.parser.SparqlParser file.
The returned query is then executed against the SPARQL endpoint or the 
Jena Model.  The SPARQL ResultSet is retrieved and the QuerySolutions stored in a local list.  A SQL ResultSet is 
created against that list and returned.


